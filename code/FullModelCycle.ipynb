{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers import Dropout, MaxPool2D, GlobalAveragePooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from tensorflow.keras.models import load_model\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to our image database\n",
    "train_path = 'E:\\Docs\\Academic\\IronHack\\Projects\\Project-Week-8-Travelling-With-Wheelchair/images/train/'\n",
    "valid_path = 'E:\\Docs\\Academic\\IronHack\\Projects\\Project-Week-8-Travelling-With-Wheelchair/images/valid/'\n",
    "test_path = 'E:\\Docs\\Academic\\IronHack\\Projects\\Project-Week-8-Travelling-With-Wheelchair/images/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1499 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Found 250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate the subsets with the train, validation and test images\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(train_path, target_size = (400,400), classes = ['ramp', 'no_ramp'], batch_size = 10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(valid_path, target_size = (400,400), classes = ['ramp', 'no_ramp'], batch_size = 10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(test_path, target_size = (400,400), classes = ['ramp', 'no_ramp'], batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build a basic model to understand how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the model and its layers\n",
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size = (3,3), activation='relu', padding='same', input_shape=(400,400,3)),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size = (3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 400, 400, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1280002   \n",
      "=================================================================\n",
      "Total params: 1,299,394\n",
      "Trainable params: 1,299,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the main information about our model: layers, data entries, parameters...\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model setting the optimizer function and our loss parameter\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 13s - loss: 89.8498 - accuracy: 0.8000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      " - 12s - loss: 11.4935 - accuracy: 0.9167 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      " - 12s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      " - 12s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      " - 12s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15d319546c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the train_batches and check its accuracy with the valid_batches\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=5, verbose=2, steps_per_epoch=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try with a more complex model (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras module with the model\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppaau\\anaconda3\\envs\\Final_project\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Define it into a variable\n",
    "resnet_model = applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=(400,400,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the model\n",
    "num_classes=2\n",
    "x = resnet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.35)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model1 = Model(inputs = resnet_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the optimizer\n",
    "from keras.optimizers import SGD, Adam\n",
    "adam = Adam()\n",
    "model1.compile(optimizer=adam, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 10909s 73s/step - loss: 0.6383 - val_loss: 65.6429\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 11830s 79s/step - loss: 0.4422 - val_loss: 12.9355\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 11543s 77s/step - loss: 0.3661 - val_loss: 11.2104\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 11231s 75s/step - loss: 0.3131 - val_loss: 0.3311\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 11300s 75s/step - loss: 0.2840 - val_loss: 1.2341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2736c5b9548>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model1.fit(train_batches, validation_data=valid_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model1.save('resnet50model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('../resnet50model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predictions into a variable\n",
    "predictions = model1.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the predicted class by rounding the predicted probability \n",
    "np.argmax(np.round(predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[58 67]\n",
      " [66 59]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix\n",
    "cm_plot_labels = ['ramp', 'no_ramp']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "final_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
